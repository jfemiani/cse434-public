{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a2d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe016dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19c0396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c98bce0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "  text = \"Your text string goes here\"\n",
    "\n",
    "  response = client.embeddings.create(\n",
    "      input=text,\n",
    "      model=\"text-embedding-ada-002\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee48ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833616b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.data[0].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b89eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings = [r.embedding for r in response.data]\n",
    "\n",
    "v = np.array(embeddings[0])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f7763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to get the vector embedding for a given text\n",
    "def get_vector_embeddings(text):\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    embeddings = [r.embedding for r in response.data]\n",
    "    return embeddings[0]\n",
    "\n",
    "get_vector_embeddings(\"Your text string goes here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a142cd23",
   "metadata": {},
   "source": [
    "Go to https://huggingface.co/settings/tokens  and get you a token.  \n",
    "Put it in your `.env` file and restart / reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f532bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "api_url = \"https://api-inference.huggingface.co/\"\n",
    "api_url += f\"pipeline/feature-extraction/{model_id}\"\n",
    "headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "\n",
    "def query(texts):\n",
    "    response = requests.post(api_url, headers=headers,\n",
    "    json={\"inputs\": texts,\n",
    "    \"options\":{\"wait_for_model\":True}})\n",
    "    return response.json()\n",
    "\n",
    "texts = [\"mickey mouse\",\n",
    "        \"cheese\",\n",
    "        \"trap\",\n",
    "        \"rat\",\n",
    "        \"ratatouille\"\n",
    "        \"bus\",\n",
    "        \"airplane\",\n",
    "        \"ship\"]\n",
    "\n",
    "output = query(texts)\n",
    "np.array(output).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gensim --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5812d27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Sample data: list of sentences, where each sentence is\n",
    "# a list of words.\n",
    "# In a real-world scenario, you'd load and preprocess your\n",
    "# own corpus.\n",
    "sentences = [\n",
    "    [\"the\", \"cake\", \"is\", \"a\", \"lie\"],\n",
    "    [\"if\", \"you\", \"hear\", \"a\", \"turret\", \"sing\", \"you're\", \"probably\", \"too\", \"close\"],\n",
    "    [\"why\", \"search\", \"for\", \"the\", \"end\", \"of\", \"a\", \"rainbow\", \"when\", \"the\", \"cake\", \"is\", \"a\", \"lie?\"],\n",
    "    [\"GLaDOS\", \"promised\", \"cake\", \"but\", \"all\", \"I\", \"got\", \"was\", \"this\", \"test\", \"chamber\"],\n",
    "    [\"remember\", \"when\", \"the\", \"platform\", \"was\", \"sliding\", \"into\", \"the\", \"fire\", \"pit\", \"and\", \"I\", \"said\", \"‘Goodbye’\", \"and\", \"you\", \"were\", \"like\", \"‘NO WAY!’\", \"and\", \"then\", \"I\", \"was\", \"all\", \"‘I\", \"was\", \"just\", \"pretending\", \"to\", \"murder\", \"you’?\", \"That\", \"was\", \"great\"],\n",
    "    [\"the\", \"cake\", \"is\", \"a\", \"lie\", \"but\", \"the\", \"companion\", \"cube\", \"is\", \"forever\"],\n",
    "    [\"wheatley\", \"might\", \"betray\", \"you,\", \"but\", \"the\", \"cake\", \"already\", \"did\"],\n",
    "    [\"if\", \"life\", \"gives\", \"you\", \"lemons,\", \"don't\", \"make\", \"a\", \"combustible\", \"lemon\"],\n",
    "    [\"there's\", \"no\", \"cake\", \"in\", \"space,\", \"just\", \"ask\", \"wheatley\"],\n",
    "    [\"completing\", \"tests\", \"for\", \"cake\", \"is\", \"the\", \"sweetest\", \"lie\"],\n",
    "    [\"I\", \"swapped\", \"the\", \"cake\", \"recipe\", \"with\", \"a\", \"neurotoxin\", \"formula,\", \"hope\", \"that's\", \"fine\"],\n",
    "] + [\n",
    "    [\"the\", \"cake\", \"is\", \"a\", \"lie\"],\n",
    "    [\"the\", \"cake\", \"is\", \"definitely\", \"a\", \"lie\"],\n",
    "    [\"everyone\", \"knows\", \"that\", \"cake\", \"equals\", \"lie\"],\n",
    "    [\"cake\", \"and\", \"lie\", \"are\", \"synonymous\"],\n",
    "    [\"whenever\", \"you\", \"hear\", \"cake\", \"think\", \"lie\"],\n",
    "    [\"cake\", \"?\", \"oh\", \"you\", \"mean\", \"lie\"],\n",
    "    [\"the\", \"truth\", \"is\", \"cake\", \"is\", \"nothing\", \"but\", \"a\", \"lie\"],\n",
    "    [\"they\", \"said\", \"cake\", \"but\", \"I\", \"heard\", \"lie\"],\n",
    "] * 10  # repeat several times to emphasize\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=100, window=5,\n",
    "min_count=1, workers=4, seed=36)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"custom_word2vec_model.model\")\n",
    "\n",
    "# To load the model later\n",
    "# loaded_model = Word2Vec.load(\"custom_word2vec_model.model\")\n",
    "\n",
    "# Get vector for a word\n",
    "vector = model.wv['cake']\n",
    "\n",
    "# Find most similar words\n",
    "similar_words = model.wv.most_similar(\"cake\", topn=5)\n",
    "print(\"Top 5 most similar words to 'cake': \")\n",
    "for match in similar_words:\n",
    "    print(\"   \", match)\n",
    "\n",
    "# Directly query the similarity between \"cake\" and \"lie\"\n",
    "cake_lie_similarity = model.wv.similarity(\"cake\", \"lie\")\n",
    "print(\"Similarity between 'cake' and 'lie': \",\n",
    "cake_lie_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85890a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb79f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Convert sentences to a list of strings for TfidfVectorizer\n",
    "document_list = [' '.join(s) for s in sentences]\n",
    "\n",
    "# Compute TF-IDF representation\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(document_list)\n",
    "\n",
    "# Extract the position of the words \"cake\" and \"lie\" in\n",
    "# the feature matrix\n",
    "cake_idx = vectorizer.vocabulary_['cake']\n",
    "lie_idx = vectorizer.vocabulary_['lie']\n",
    "\n",
    "# Extract and reshape the vector for 'cake'\n",
    "cakevec = tfidf_matrix[:, cake_idx].toarray().reshape(1, -1)\n",
    "\n",
    "# Compute the cosine similarities\n",
    "similar_words = cosine_similarity(cakevec, tfidf_matrix.T).flatten()\n",
    "\n",
    "# Get the indices of the top 6 most similar words\n",
    "# (including 'cake')\n",
    "top_indices = np.argsort(similar_words)[-6:-1][::-1]\n",
    "\n",
    "# Retrieve and print the top 5 most similar words to\n",
    "# 'cake' (excluding 'cake' itself)\n",
    "names = []\n",
    "for idx in top_indices:\n",
    "    names.append(vectorizer.get_feature_names_out()[idx])\n",
    "print(\"Top 5 most similar words to 'cake': \", names)\n",
    "\n",
    "# Compute cosine similarity between \"cake\" and \"lie\"\n",
    "similarity = cosine_similarity(np.asarray(tfidf_matrix[:,\n",
    "    cake_idx].todense()), np.asarray(tfidf_matrix[:, lie_idx].todense()))\n",
    "# The result will be a matrix; we can take the average or\n",
    "# max similarity value\n",
    "avg_similarity = similarity.mean()\n",
    "print(\"Similarity between 'cake' and 'lie'\", avg_similarity)\n",
    "\n",
    "# Show the similarity between \"cake\" and \"elephant\"\n",
    "elephant_idx = vectorizer.vocabulary_['sing']\n",
    "similarity = cosine_similarity(np.asarray(tfidf_matrix[:,\n",
    "    cake_idx].todense()), np.asarray(tfidf_matrix[:,\n",
    "    elephant_idx].todense()))\n",
    "avg_similarity = similarity.mean()\n",
    "print(\"Similarity between 'cake' and 'sing'\",\n",
    "    avg_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09881a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
