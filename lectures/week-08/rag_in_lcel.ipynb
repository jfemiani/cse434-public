{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install faiss-cpu --quiet\n",
    "# %pip install faiss-gpu --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0be756",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install dotenv langchain_community langchain langchain_openai --quiet --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "for key in ['OPENAI_API_KEY']:\n",
    "    if not key in os.environ:\n",
    "        try:\n",
    "            from google.colab import userdata\n",
    "            os.environ[key] = userdata.get(key)\n",
    "        except:\n",
    "            print(f\"You need to set the {key} key either in colab or in a .env var.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e156348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "documents = [\n",
    "    \"James Phoenix worked at JustUnderstandingData.\",\n",
    "    \"James phoenix currently is 31 years old.\",\n",
    "    \"Data engineering is the designing and building systems for collecting, storing, and analysing data at scale.\",\n",
    "]\n",
    "\n",
    "vectorstore = FAISS.from_texts(texts=documents, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "---\n",
    "Context: {context}\n",
    "---\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ded747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to this chain is just a  string \"What is data engineering\"\n",
    "chain = (\n",
    "    # We build a dictionary as input to the prompt template\n",
    "    {\n",
    "        # We add the key 'context' and set ist value\n",
    "        \"context\": retriever,\n",
    "        # We add the key 'question' and set it to the input of the chain\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090986f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chain.invoke(\"What is data engineering?\")\n",
    "import textwrap\n",
    "print(textwrap.fill(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27cb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chain.invoke(\"Who is James Phoenix?\")\n",
    "print(textwrap.fill(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ae9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chain.invoke(\"What is the president of the US?\") # Testing for fake knowledge\n",
    "print(textwrap.fill(res))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
