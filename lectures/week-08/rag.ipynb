{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ccd75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "for key in ['OPENAI_API_KEY']:\n",
    "    if not key in os.environ:\n",
    "        try:\n",
    "            from google.colab import userdata\n",
    "            os.environ[key] = userdata.get(key)   \n",
    "        except:\n",
    "            print(f\"You need to set the {key} key either in colab or in a .env var.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615bfda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to get the vector embedding for a given text\n",
    "def get_vector_embeddings(text):\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    embeddings = [r.embedding for r in response.data]\n",
    "    return embeddings[0]\n",
    "\n",
    "get_vector_embeddings(\"Your text string goes here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3273a74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=100,  # 100 tokens\n",
    "    chunk_overlap=20,  # 20 tokens of overlap\n",
    ")\n",
    "\n",
    "text = \"\"\"\n",
    "Welcome to the \"Unicorn Enterprises: Where Magic Happens\" Employee Handbook! We're thrilled to have you join our team of dreamers, doers, and unicorn enthusiasts. At Unicorn Enterprises, we believe that work should be as enchanting as it is productive. This handbook is your ticket to the magical world of our company, where we'll outline the principles, policies, and practices that guide us on this extraordinary journey. So, fasten your seatbelts and get ready to embark on an adventure like no other!\n",
    "Certainly, here are five middle paragraphs for your fake employee handbook:\n",
    "\n",
    "**1: Our Magical Culture**\n",
    "\n",
    "At Unicorn Enterprises, we take pride in our unique and enchanting company culture. We believe that creativity and innovation flourish best when people are happy and inspired. From our weekly \"Wear Your Favorite Mythical Creature Costume\" day on Fridays to our in-house unicorn petting zoo, we aim to infuse magic into every corner of our workplace. So, don't be surprised if you find a fairy tale book in the breakroom or a gnome guiding you to the restroom. Our culture is designed to spark your imagination and encourage collaboration among our magical team.\n",
    "\n",
    "**2: Unicorn Code of Conduct**\n",
    "\n",
    "While we embrace creativity, we also value professionalism. Our Unicorn Code of Conduct ensures that we maintain a harmonious and respectful environment. Treating all team members, regardless of their unicorn species, with kindness and respect is essential. We also encourage open communication and constructive feedback because, in our world, every opinion matters, just like every horn on a unicorn's head!\n",
    "\n",
    "**3: Magical Work-Life Balance**\n",
    "\n",
    "At Unicorn Enterprises, we understand the importance of maintaining a balanced life. We offer flexible work hours, magical mental health days, and even an on-site wizard to provide stress-relief spells when needed. We believe that a happy and well-rested employee is a creative and productive employee. So, don't hesitate to use our relaxation chambers or join a group meditation session under the office rainbow.\n",
    "\n",
    "**4: Enchanted Benefits**\n",
    "\n",
    "Our commitment to your well-being extends to our magical benefits package. You'll enjoy a treasure chest of perks, including unlimited unicorn rides, a bottomless cauldron of coffee and potions, and access to our company library filled with spellbinding books. We also offer competitive health and dental plans, ensuring your physical well-being is as robust as your magical spirit.\n",
    "\n",
    "**5: Continuous Learning and Growth**\n",
    "\n",
    "At Unicorn Enterprises, we believe in continuous learning and growth. We provide access to a plethora of online courses, enchanted workshops, and wizard-led training sessions. Whether you're aspiring to master new spells or conquer new challenges, we're here to support your personal and professional development.\n",
    "\n",
    "As we conclude this handbook, remember that at Unicorn Enterprises, the pursuit of excellence is a never-ending quest. Our company's success depends on your passion, creativity, and commitment to making the impossible possible. We encourage you to always embrace the magic within and outside of work, and to share your ideas and innovations to keep our enchanted journey going. Thank you for being a part of our mystical family, and together, we'll continue to create a world where magic and business thrive hand in hand!\n",
    "\"\"\"\n",
    "\n",
    "from textwrap import fill\n",
    "chunks = text_splitter.split_text(text=text)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(fill(f'[{i:3}] : {chunk}', subsequent_indent=' '*8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4016253",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install faiss-cpu --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335e7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Get vector embeddings for the chunks from last example\n",
    "emb = [get_vector_embeddings(chunk) for chunk in chunks]\n",
    "vectors = np.array(emb)\n",
    "\n",
    "# Create a FAISS index\n",
    "index = faiss.IndexFlatL2(vectors.shape[1])\n",
    "index.add(vectors)\n",
    "\n",
    "# Function to perform a vector search\n",
    "def vector_search(query_text, k=1):\n",
    "    query_vector = get_vector_embeddings(query_text)\n",
    "    distances, indices = index.search(\n",
    "        np.array([query_vector]), k)\n",
    "    return [(chunks[i], float(dist)) for dist, \n",
    "        i in zip(distances[0], indices[0])]\n",
    "\n",
    "# Example search\n",
    "user_query = \"do we get free unicorn rides?\"\n",
    "search_results = vector_search(user_query)\n",
    "print(f\"Search results for {user_query}:\", search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ca1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform a vector search and then ask # GPT-3.5-turbo a question:\n",
    "def search_and_chat(user_query, k=1):\n",
    "  \n",
    "  # Perform the vector search\n",
    "  search_results = vector_search(user_query, k)\n",
    "  print(f\"Search results: {search_results}\\n\\n\")\n",
    "\n",
    "  prompt_with_context = f\"\"\"Context:{search_results}\\\n",
    "  Answer the question: {user_query}\"\"\"\n",
    "  \n",
    "  # Create a list of messages for the chat\n",
    "  messages = [\n",
    "      {\"role\": \"system\", \"content\": \"\"\"Please answer the\n",
    "      questions provided by the user. Use only the context\n",
    "      provided to you to respond to the user, if you don't\n",
    "      know the answer say \\\"I don't know\\\".\"\"\"},\n",
    "      {\"role\": \"user\", \"content\": prompt_with_context},\n",
    "  ]\n",
    "\n",
    "  # Get the model's response\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", messages=messages)\n",
    "\n",
    "  # Print the assistant's reply\n",
    "  print(f\"\"\"Response: \n",
    "  {response.choices[0].message.content}\"\"\")\n",
    "\n",
    "# Example search and chat\n",
    "search_and_chat(\"How often can I wear a costume to work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e312cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the index to a file\n",
    "faiss.write_index(index, \"my_index_file.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7cac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the index from a file\n",
    "index = faiss.read_index(\"my_index_file.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4f020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
